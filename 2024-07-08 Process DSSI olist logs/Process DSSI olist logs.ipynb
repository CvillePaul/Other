{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "import re\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, explore around to determine how to identify lines representing observations vs other lines in the log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how to find log lines representing observations vs log lines describing procedures\n",
    "logs_dir = r\"..\\..\\Files\\DSSI Logs\"\n",
    "logs_to_process = glob(f\"{logs_dir}/**/*.olist\", recursive=True)\n",
    "\n",
    "observation_lines = \"DSSI observations.txt\"\n",
    "other_lines = \"Non observation lines.txt\"\n",
    "\n",
    "with open(observation_lines, mode=\"w\") as obs, open(other_lines, mode=\"w\") as non_obs:\n",
    "    for file in logs_to_process:\n",
    "        datestr = ''.join(re.findall(\"([0-9]{4})....(...[0-9]{2})\", file)[0])\n",
    "        utc_date = datetime.strptime(datestr, \"%Y%b%d\")\n",
    "        with open(file) as f:\n",
    "            title = f\"===========\\nFile {file} from {utc_date}\\n===========\"\n",
    "            obs.write(title + \"\\n\")\n",
    "            non_obs.write(title + \"\\n\")\n",
    "            for line in f.readlines():\n",
    "                if line.count(\":\") >= 4: # and line.count(\"TIC\") > 0:\n",
    "                    obs.write(f\"{datestr} {line}\")\n",
    "                else:\n",
    "                    non_obs.write(line)\n",
    "\n",
    "# Conclusion: requiring 4 or more colon characters exactly splits the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now extract all observation lines from all files\n",
    "* Use more than one regex to match the target lines\n",
    "  * For speed, make first regex attempted be the one that is empirically observed to match the most lines\n",
    "* Keep track of lines that \"fall through\" and aren't matched by any regex pattern\n",
    "* Standardize things for easier use in analysis\n",
    "  * Output times both in ISO format and in JD\n",
    "  * Convert sexagesimal coordinates to decimal degrees\n",
    "* \"Explode\" each observation line into multiple lines, one for each wavelength involved (typically 2 or 3)\n",
    "  * Currently, wavelength values are hard coded at the top of this code.\n",
    "  * Scanning all log files for lines with \"Camera A =\" (or B), all files unsurprisingly cite the same set of wavelengths\n",
    "* Output a CSV of all parsed & standardized observation lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  81 Single Gain Value\n",
      " 344 No Image Num or Gains\n",
      "3846 Standard Pattern\n",
      " 134 Infrared Observations\n",
      "\n",
      "9 failed matches\n",
      "HR 3366 053-056 014    0      08:32:42.5 +20:26:28.0      0.000     0.000  5.33  Slit mask\n",
      "H900004 XXX-XXX 027 12:36 XXX  15:43:48.5 +25:52:38.3   -171.0     317.0   14.33  2MASS J15434848+2552376  -  Pokemon\n",
      "H900004 XXX-XXX 028 12:43 XXX  15:43:48.5 +25:52:38.3   -171.0     317.0   14.33  2MASS J15434848+2552376  -  Pokemon\n",
      "HR 0689 116 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  \n",
      "HR 0689 117 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in Y (South)\n",
      "HR 0689 118 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  +5\" in Y (North)\n",
      "HR 0689 119 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in X (West)\n",
      "HR 0689 120 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  +5\" in X (East)\n",
      "HR 0689 121 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in X (West)\n"
     ]
    }
   ],
   "source": [
    "# now extract useful information from the various lines\n",
    "\n",
    "logs_dir = r\"..\\..\\Files\\DSSI Logs\"\n",
    "logs_to_process = glob(f\"{logs_dir}/**/*.olist\", recursive=True)\n",
    "# logs_to_process = ['foo.olist']\n",
    "\n",
    "filter_blue = 692\n",
    "filter_red = 880\n",
    "filter_ir = 1450\n",
    "\n",
    "dssi_observations = Table(\n",
    "    names=[\"Target Name\", \"TIC ID\", \"Wavelength\", \"Image Number\", \"UTC DateTime\", \"Time JD\", \"Gain 1\", \"Gain 2\", \"RA\", \"Dec\", \"PMRA\", \"PMDec\", \"Mag\", \"Notes\", ],\n",
    "    dtype=[\"str\", \"str\", \"int\", \"int\", \"str\", \"float\", \"int\", \"int\", \"float\", \"float\", \"float\", \"float\", \"float\", \"str\", ],\n",
    ")\n",
    "\n",
    "line_counts = Counter()\n",
    "failed_lines = []\n",
    "for file in logs_to_process:\n",
    "    with open(file) as f:\n",
    "        datestr = ''.join(re.findall(\"([0-9]{4})....(...[0-9]{2})\", file)[0])\n",
    "        utc_date = datetime.strptime(datestr, \"%Y%b%d\")\n",
    "        for line in f.readlines():\n",
    "            fields = {}\n",
    "            if line.count(\":\") < 4: # all observation lines follow this pattern\n",
    "                continue # skip non-observation lines\n",
    "            if match := re.match(r\"(?P<target_name>.{7,13})\\s+(?P<image_num>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<gain_1>\\d{1,3})\\s+(?P<gain_2>\\d{1,3})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9.+-]*)\\s+(?P<pmdec>[0-9.+-]*)\\s+(?P<mag>[0-9.-]+)\\s*(?P<notes>.*)\", line):\n",
    "                line_counts[\"Standard Pattern\"] += 1\n",
    "            elif match := re.match(r\"(?P<target_name>\\\"{0,1}.{7,13}\\\"{0,1})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9.+-]*)\\s+(?P<pmdec>[0-9.+-]*)\\s+(?P<mag>[0-9.-]+)\\s*(?P<notes>.*)\", line):\n",
    "                fields[\"image_num\"] = 0\n",
    "                fields[\"gain_1\"] = 0\n",
    "                fields[\"gain_2\"] = 0\n",
    "                line_counts[\"No Image Num or Gains\"] += 1\n",
    "            elif match := re.match(r\"(?P<target_name>.{7})\\s+(?P<image_beg>\\d{1,3})-(?P<image_end>\\d{1,3})\\s+(?P<image_ir>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<gain>\\d{1,3})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9\\.+-]*)\\s+(?P<pmdec>[0-9\\.+-]*)\\s+(?P<mag>[0-9\\.]+)\\s*(?P<notes>.*)\", line):\n",
    "                line_counts[\"Infrared Observations\"] += 1\n",
    "            elif match := re.match(r\"(?P<target_name>\\\".{7}\\\")\\s+(?P<image_num>\\d{1,3})\\s+(?P<gain>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9\\.+-]*)\\s+(?P<pmdec>[0-9\\.+-]*)\\s+(?P<mag>[0-9\\.]+)\\s*(?P<notes>.*)\", line): #\n",
    "                line_counts[\"Single Gain Value\"] += 1\n",
    "            if match:\n",
    "                fields = {**match.groupdict(), **fields}\n",
    "                try:\n",
    "                    if not \"pmra\" in fields or fields[\"pmra\"] == \"\":\n",
    "                        fields[\"pmra\"] = 0\n",
    "                        fields[\"pmdec\"] = 0\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                if \"gain\" in fields: # assume gains are the same for both arms if only one gain specified\n",
    "                    fields[\"gain_1\"] = fields[\"gain\"]\n",
    "                    fields[\"gain_2\"] = fields[\"gain\"]\n",
    "                if \"hours\" in fields:\n",
    "                    obs_time = Time(utc_date + timedelta(hours=int(fields[\"hours\"]), minutes=int(fields[\"minutes\"])))\n",
    "                    datetime_utc = str(obs_time.utc)\n",
    "                    datetime_jd = obs_time.jd\n",
    "                else:\n",
    "                    datetime_utc = \"\"\n",
    "                    datetime_jd = 0\n",
    "                if \"image_ir\" in fields:\n",
    "                    observations = [(fields[\"image_ir\"], filter_ir)]\n",
    "                    observations += [(image_num, filter_x)\n",
    "                                     for filter_x in [filter_red, filter_blue]\n",
    "                                     for image_num in range(int(fields[\"image_beg\"]), int(fields[\"image_end\"]) + 1)\n",
    "                                     ]\n",
    "                else:\n",
    "                    image_num = fields[\"image_num\"]\n",
    "                    observations = [(image_num, filter_blue), (image_num, filter_red)]\n",
    "                coord = SkyCoord(ra=fields[\"ra\"], dec=fields[\"dec\"], unit=(u.hourangle, u.deg))\n",
    "                if matches := re.findall('TIC ?(?:ID)? ?=? ?([0-9]+)', line):\n",
    "                    fields[\"tic_id\"] = \"TIC \" + matches[0]\n",
    "                else:\n",
    "                    fields[\"tic_id\"] = \"\"\n",
    "                for (image_num, wavelength) in observations:\n",
    "                    try:\n",
    "                        dssi_observations.add_row([fields[\"target_name\"].replace('\"', ''), fields[\"tic_id\"], wavelength, image_num, datetime_utc, datetime_jd, fields[\"gain_1\"], fields[\"gain_2\"], coord.ra, coord.dec, float(fields[\"pmra\"]), float(fields[\"pmdec\"]), fields[\"mag\"], fields[\"notes\"]])\n",
    "                    except Exception as e:\n",
    "                        print(\"error:\", fields[\"tic_id\"], line[:-1])\n",
    "            else:\n",
    "                failed_lines.append(line)\n",
    "for (regex, count) in line_counts.items():\n",
    "    print(f\"{count:4d} {regex}\")\n",
    "print()\n",
    "print(len(failed_lines), \"failed matches\")\n",
    "for failed_line in failed_lines:\n",
    "    print(failed_line[:-1])\n",
    "dssi_observations.sort(\"Time JD\")\n",
    "dssi_observations.write(\"DSSI Observations.csv\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now collect observations into *sessions*\n",
    "A session:\n",
    "* is on the same target\n",
    "* is one or more speckle observations taken back to back (no other objects targeted in between)\n",
    "* contains measurements at one or more wavelength, typically 2 but sometimes 3 if the IR arm is used\n",
    "\n",
    "Each (target + session + wavelength) combination results in one line in the sessions table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the observations by (target, wavelength) sequences\n",
    "\n",
    "# first, add a speckle session column that changes with each new target\n",
    "prev_target = \"\"\n",
    "speckle_session = 0\n",
    "dssi_observations[\"Speckle Session\"] = 0\n",
    "dssi_observations.sort(\"Time JD\")\n",
    "for observation in dssi_observations:\n",
    "    target_name = observation[\"Target Name\"]\n",
    "    if target_name != prev_target:\n",
    "        speckle_session += 1\n",
    "        prev_target = target_name\n",
    "    observation[\"Speckle Session\"] = speckle_session\n",
    "\n",
    "dssi_observations[[\"Target Name\", \"Speckle Session\"]]\n",
    "\n",
    "# now, make a group summary of each wavelength in a speckle session\n",
    "dssi_sessions = Table(\n",
    "    names=[\"Target Name\", \"TIC ID\", \"Speckle Session\", \"Wavelength\", \"StartTime JD\", \"MidTime JD\", \"EndTime JD\", \"MidTime UTC\", \"Num Sequences\"],\n",
    "    dtype=[\"str\", \"str\", \"str\", \"int\", \"float\", \"float\", \"float\", \"str\", \"int\"],\n",
    ")\n",
    "\n",
    "obs_by_session = dssi_observations.group_by([\"Speckle Session\", \"Target Name\", \"Wavelength\", \"TIC ID\"])\n",
    "for keys, observations in zip(obs_by_session.groups.keys, obs_by_session.groups):\n",
    "    start_time = observations[\"Time JD\"].min()\n",
    "    end_time = observations[\"Time JD\"].max()\n",
    "    mid_time = (end_time + start_time) / 2\n",
    "    mid_utc = str(Time(mid_time, format=\"jd\").iso)[:19] if mid_time > 0 else \"\"\n",
    "    dssi_sessions.add_row((keys[\"Target Name\"], keys[\"TIC ID\"], str(keys[\"Speckle Session\"]), keys[\"Wavelength\"], start_time, mid_time, end_time, mid_utc, len(observations)))\n",
    "\n",
    "dssi_sessions.write(\"DSSI sessions.csv\", overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
