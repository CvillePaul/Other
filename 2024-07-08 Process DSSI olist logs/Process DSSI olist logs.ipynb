{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "import re\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, explore around to determine how to identify lines representing observations vs other lines in the log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how to find log lines representing observations vs log lines describing procedures\n",
    "logs_dir = r\"..\\..\\Files\\DSSI Logs\"\n",
    "logs_to_process = glob(f\"{logs_dir}/**/*.olist\", recursive=True)\n",
    "\n",
    "observation_lines = \"DSSI observations.txt\"\n",
    "other_lines = \"Non observation lines.txt\"\n",
    "\n",
    "with open(observation_lines, mode=\"w\") as obs, open(other_lines, mode=\"w\") as non_obs:\n",
    "    for file in logs_to_process:\n",
    "        datestr = ''.join(re.findall(\"([0-9]{4})....(...[0-9]{2})\", file)[0])\n",
    "        utc_date = datetime.strptime(datestr, \"%Y%b%d\")\n",
    "        with open(file) as f:\n",
    "            title = f\"===========\\nFile {file} from {utc_date}\\n===========\"\n",
    "            obs.write(title + \"\\n\")\n",
    "            non_obs.write(title + \"\\n\")\n",
    "            for line in f.readlines():\n",
    "                if line.count(\":\") >= 4: # and line.count(\"TIC\") > 0:\n",
    "                    obs.write(f\"{datestr} {line}\")\n",
    "                else:\n",
    "                    non_obs.write(line)\n",
    "\n",
    "# Conclusion: requiring 4 or more colon characters exactly splits the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now extract all observation lines from all files\n",
    "* Use more than one regex to match the target lines\n",
    "  * For speed, make first regex attempted be the one that is empirically observed to match the most lines\n",
    "* Keep track of lines that \"fall through\" and aren't matched by any regex pattern\n",
    "* Standardize things for easier use in analysis\n",
    "  * Output times both in ISO format and in JD\n",
    "  * Convert sexagesimal coordinates to decimal degrees\n",
    "* Depending on if the pattern matching a line includes IR information or not, add a comma-separated list of wavelengths\n",
    "  * Currently, wavelength values are hard coded at the top of this code.\n",
    "  * Scanning all log files for lines with \"Camera A =\" (or B), all files unsurprisingly cite the same set of wavelengths\n",
    "* Output a CSV of all parsed & standardized observation lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  81 Single Gain Value\n",
      " 344 No Image Num or Gains\n",
      "3846 Standard Pattern\n",
      " 134 Infrared Observations\n",
      "Total lines identified as observations: 4405\n",
      "\n",
      "9 failed matches\n",
      "HR 3366 053-056 014    0      08:32:42.5 +20:26:28.0      0.000     0.000  5.33  Slit mask\n",
      "H900004 XXX-XXX 027 12:36 XXX  15:43:48.5 +25:52:38.3   -171.0     317.0   14.33  2MASS J15434848+2552376  -  Pokemon\n",
      "H900004 XXX-XXX 028 12:43 XXX  15:43:48.5 +25:52:38.3   -171.0     317.0   14.33  2MASS J15434848+2552376  -  Pokemon\n",
      "HR 0689 116 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  \n",
      "HR 0689 117 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in Y (South)\n",
      "HR 0689 118 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  +5\" in Y (North)\n",
      "HR 0689 119 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in X (West)\n",
      "HR 0689 120 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  +5\" in X (East)\n",
      "HR 0689 121 08:            02:21:56.6 +00:23:45.0      0.000     0.000  5.00  -5\" in X (West)\n"
     ]
    }
   ],
   "source": [
    "# now extract useful information from the various lines\n",
    "\n",
    "logs_dir = r\"..\\..\\Files\\DSSI Logs\"\n",
    "logs_to_process = glob(f\"{logs_dir}/**/*.olist\", recursive=True)\n",
    "# logs_to_process = ['foo.olist']\n",
    "\n",
    "wavelengths_optical = \"692, 880\"\n",
    "wavelengths_ir = \"1450\"\n",
    "\n",
    "dssi_observations = Table(\n",
    "    names=[\"Target Name\", \"TIC ID\", \"Wavelengths\", \"Image Number\", \"UTC DateTime\", \"Time JD\", \"Gain 1\", \"Gain 2\", \"RA\", \"Dec\", \"PMRA\", \"PMDec\", \"Mag\", \"Notes\", ],\n",
    "    dtype=[\"str\", \"str\", \"str\", \"int\", \"str\", \"float\", \"int\", \"int\", \"float\", \"float\", \"float\", \"float\", \"float\", \"str\", ],\n",
    ")\n",
    "\n",
    "line_counts = Counter()\n",
    "failed_lines = []\n",
    "for file in logs_to_process:\n",
    "    with open(file) as f:\n",
    "        datestr = ''.join(re.findall(\"([0-9]{4})....(...[0-9]{2})\", file)[0])\n",
    "        utc_date = datetime.strptime(datestr, \"%Y%b%d\")\n",
    "        for line in f.readlines():\n",
    "            fields = {}\n",
    "            if line.count(\":\") < 4: # all observation lines follow this pattern\n",
    "                continue # skip non-observation lines\n",
    "            if match := re.match(r\"(?P<target_name>.{7,13})\\s+(?P<image_num>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<gain_1>\\d{1,3})\\s+(?P<gain_2>\\d{1,3})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9.+-]*)\\s+(?P<pmdec>[0-9.+-]*)\\s+(?P<mag>[0-9.-]+)\\s*(?P<notes>.*)\", line):\n",
    "                line_counts[\"Standard Pattern\"] += 1\n",
    "            elif match := re.match(r\"(?P<target_name>\\\"{0,1}.{7,13}\\\"{0,1})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9.+-]*)\\s+(?P<pmdec>[0-9.+-]*)\\s+(?P<mag>[0-9.-]+)\\s*(?P<notes>.*)\", line):\n",
    "                line_counts[\"No Image Num or Gains\"] += 1\n",
    "                continue # per Jimmy, these were possible targets that never resulted in an actual observation\n",
    "            elif match := re.match(r\"(?P<target_name>.{7})\\s+(?P<image_beg>\\d{1,3})-(?P<image_end>\\d{1,3})\\s+(?P<image_ir>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<gain>\\d{1,3})\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9\\.+-]*)\\s+(?P<pmdec>[0-9\\.+-]*)\\s+(?P<mag>[0-9\\.]+)\\s*(?P<notes>.*)\", line):\n",
    "                line_counts[\"Infrared Observations\"] += 1\n",
    "            elif match := re.match(r\"(?P<target_name>\\\".{7}\\\")\\s+(?P<image_num>\\d{1,3})\\s+(?P<gain>\\d{1,3})\\s+(?P<hours>\\d\\d):(?P<minutes>\\d\\d)\\s+(?P<ra>\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<dec>[+|-]{0,1}\\d\\d:\\d\\d:\\d\\d\\.\\d+)\\s+(?P<pmra>[0-9\\.+-]*)\\s+(?P<pmdec>[0-9\\.+-]*)\\s+(?P<mag>[0-9\\.]+)\\s*(?P<notes>.*)\", line): #\n",
    "                line_counts[\"Single Gain Value\"] += 1\n",
    "            if match:\n",
    "                fields = {**match.groupdict(), **fields}\n",
    "                try:\n",
    "                    if not \"pmra\" in fields or fields[\"pmra\"] == \"\":\n",
    "                        fields[\"pmra\"] = 0\n",
    "                        fields[\"pmdec\"] = 0\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                if \"gain\" in fields: # assume gains are the same for both arms if only one gain specified\n",
    "                    fields[\"gain_1\"] = fields[\"gain\"]\n",
    "                    fields[\"gain_2\"] = fields[\"gain\"]\n",
    "                if \"hours\" in fields:\n",
    "                    obs_time = Time(utc_date + timedelta(hours=int(fields[\"hours\"]), minutes=int(fields[\"minutes\"])))\n",
    "                    datetime_utc = str(obs_time.utc)\n",
    "                    datetime_jd = obs_time.jd\n",
    "                else:\n",
    "                    datetime_utc = str(utc_date)\n",
    "                    datetime_jd = 0\n",
    "                if \"image_ir\" in fields:\n",
    "                    observations = [(image_num, wavelengths_optical) for image_num in range(int(fields[\"image_beg\"]), int(fields[\"image_end\"]) + 1)]\n",
    "                    observations.append((fields[\"image_ir\"], wavelengths_ir))\n",
    "                else:\n",
    "                    observations = [(fields[\"image_num\"], wavelengths_optical)]\n",
    "                coord = SkyCoord(ra=fields[\"ra\"], dec=fields[\"dec\"], unit=(u.hourangle, u.deg))\n",
    "                if matches := re.findall('TIC ?(?:ID)? ?=? ?([0-9]+)', line):\n",
    "                    fields[\"tic_id\"] = \"TIC \" + matches[0]\n",
    "                else:\n",
    "                    fields[\"tic_id\"] = \"\"\n",
    "                for image_num, wavelengths in observations:\n",
    "                    try:\n",
    "                        dssi_observations.add_row([fields[\"target_name\"].replace('\"', ''), fields[\"tic_id\"], wavelengths, image_num, datetime_utc, datetime_jd, fields[\"gain_1\"], fields[\"gain_2\"], coord.ra, coord.dec, float(fields[\"pmra\"]), float(fields[\"pmdec\"]), fields[\"mag\"], fields[\"notes\"]])\n",
    "                    except Exception as e:\n",
    "                        print(\"error:\", fields[\"tic_id\"], line[:-1])\n",
    "            else:\n",
    "                failed_lines.append(line)\n",
    "total_observation_lines = 0\n",
    "for (regex, count) in line_counts.items():\n",
    "    print(f\"{count:4d} {regex}\")\n",
    "    total_observation_lines += count\n",
    "print(f\"Total lines identified as observations: {total_observation_lines}\")\n",
    "print()\n",
    "print(len(failed_lines), \"failed matches\")\n",
    "for failed_line in failed_lines:\n",
    "    print(failed_line[:-1])\n",
    "dssi_observations.sort(\"Time JD\")\n",
    "dssi_observations.write(\"DSSI Observations.csv\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above count of lines of observations is smaller than the number of lines output to the `DSSI observations.csv` file.  This is because each line of IR observation results in *n* lines of optical observation and one line of IR observation.  Doing otherwise would require throwing away the image numbers.  Preserving them in the CSV file makes future projects easier, such as correlating the FITS files from the cameras to these records of observations.\n",
    "\n",
    "## Now collect observations into *sessions*\n",
    "A session:\n",
    "* is on the same target\n",
    "* is one or more speckle observations taken back to back (no other objects targeted in between)\n",
    "* contains measurements at one or more wavelength, typically 2 but sometimes 3 if the IR arm is used\n",
    "\n",
    "Each (target + session) combination results in one line in the sessions table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4597</i>\n",
       "<table id=\"table2825287666144\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Target Name</th><th>TIC ID</th><th>Wavelengths</th><th>Image Number</th><th>UTC DateTime</th><th>Time JD</th><th>Gain 1</th><th>Gain 2</th><th>RA</th><th>Dec</th><th>PMRA</th><th>PMDec</th><th>Mag</th><th>Notes</th><th>Speckle Session</th></tr></thead>\n",
       "<thead><tr><th>str12</th><th>str13</th><th>str8</th><th>int32</th><th>str19</th><th>float64</th><th>int32</th><th>int32</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str55</th><th>int32</th></tr></thead>\n",
       "<tr><td>HR  583</td><td></td><td>692, 880</td><td>1</td><td>2022-09-27 07:45:00</td><td>2459849.8229166665</td><td>20</td><td>20</td><td>29.94208333333333</td><td>-20.824444444444445</td><td>18.826</td><td>15.86</td><td>5.41</td><td></td><td>1</td></tr>\n",
       "<tr><td>H007396</td><td></td><td>692, 880</td><td>2</td><td>2022-09-27 07:49:00</td><td>2459849.8256944446</td><td>20</td><td>20</td><td>23.8375</td><td>-21.201083333333333</td><td>140.035</td><td>-73.844</td><td>8.75</td><td>Xavier</td><td>2</td></tr>\n",
       "<tr><td>H200063</td><td></td><td>692, 880</td><td>3</td><td>2022-09-27 07:54:00</td><td>2459849.8291666666</td><td>100</td><td>100</td><td>33.94208333333333</td><td>-18.23813888888889</td><td>-33.316</td><td>-124.197</td><td>8.09</td><td>pri1 RKS0215-1814</td><td>3</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>4</td><td>2022-09-27 07:59:00</td><td>2459849.832638889</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=0</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>5</td><td>2022-09-27 08:04:00</td><td>2459849.836111111</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=-30</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>6</td><td>2022-09-27 08:08:00</td><td>2459849.8388888887</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=-60</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>7</td><td>2022-09-27 08:11:00</td><td>2459849.8409722224</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=-90</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>8</td><td>2022-09-27 08:14:00</td><td>2459849.8430555556</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=-120</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>9</td><td>2022-09-27 08:16:00</td><td>2459849.8444444444</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=-150</td><td>4</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>692, 880</td><td>10</td><td>2022-09-27 08:22:00</td><td>2459849.8486111113</td><td>100</td><td>100</td><td>36.94125</td><td>4.432138888888889</td><td>86.42</td><td>240.0</td><td>8.67</td><td>SCALE, rho=0.618±0.058, rot=0</td><td>4</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>H101769</td><td></td><td>692, 880</td><td>302</td><td>2024-05-28 11:22:00</td><td>2460458.9736111113</td><td>2</td><td>2</td><td>309.3870833333333</td><td>14.595083333333333</td><td>118.09</td><td>-48.06</td><td>3.63</td><td>SCALE,rho=0.40&quot;,rot=+90</td><td>2192</td></tr>\n",
       "<tr><td>H101769</td><td></td><td>692, 880</td><td>303</td><td>2024-05-28 11:25:00</td><td>2460458.9756944445</td><td>2</td><td>2</td><td>309.3870833333333</td><td>14.595083333333333</td><td>118.09</td><td>-48.06</td><td>3.63</td><td>SCALE,rho=0.40&quot;,rot=+135</td><td>2192</td></tr>\n",
       "<tr><td>H101769</td><td></td><td>692, 880</td><td>304</td><td>2024-05-28 11:29:00</td><td>2460458.978472222</td><td>2</td><td>2</td><td>309.3870833333333</td><td>14.595083333333333</td><td>118.09</td><td>-48.06</td><td>3.63</td><td>SCALE,rho=0.40&quot;,rot=0</td><td>2192</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>305</td><td>2024-05-28 11:31:00</td><td>2460458.979861111</td><td>2</td><td>2</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td></td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>306</td><td>2024-05-28 11:36:00</td><td>2460458.9833333334</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>307</td><td>2024-05-28 11:38:00</td><td>2460458.984722222</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>308</td><td>2024-05-28 11:39:00</td><td>2460458.9854166666</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>309</td><td>2024-05-28 11:41:00</td><td>2460458.9868055554</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>310</td><td>2024-05-28 11:43:00</td><td>2460458.988194444</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>692, 880</td><td>311</td><td>2024-05-28 11:45:00</td><td>2460458.9895833335</td><td>300</td><td>300</td><td>313.90291666666667</td><td>13.721388888888889</td><td>0.0</td><td>0.0</td><td>5.17</td><td>Slit mask</td><td>2193</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4597>\n",
       "Target Name TIC ID ...              Notes               Speckle Session\n",
       "   str12    str13  ...              str55                    int32     \n",
       "----------- ------ ... -------------------------------- ---------------\n",
       "    HR  583        ...                                                1\n",
       "    H007396        ...                           Xavier               2\n",
       "    H200063        ...                pri1 RKS0215-1814               3\n",
       "    H011452        ...    SCALE, rho=0.618±0.058, rot=0               4\n",
       "    H011452        ...  SCALE, rho=0.618±0.058, rot=-30               4\n",
       "    H011452        ...  SCALE, rho=0.618±0.058, rot=-60               4\n",
       "    H011452        ...  SCALE, rho=0.618±0.058, rot=-90               4\n",
       "    H011452        ... SCALE, rho=0.618±0.058, rot=-120               4\n",
       "    H011452        ... SCALE, rho=0.618±0.058, rot=-150               4\n",
       "    H011452        ...    SCALE, rho=0.618±0.058, rot=0               4\n",
       "        ...    ... ...                              ...             ...\n",
       "    H101769        ...          SCALE,rho=0.40\",rot=+90            2192\n",
       "    H101769        ...         SCALE,rho=0.40\",rot=+135            2192\n",
       "    H101769        ...            SCALE,rho=0.40\",rot=0            2192\n",
       "    HR 8011        ...                                             2193\n",
       "    HR 8011        ...                        Slit mask            2193\n",
       "    HR 8011        ...                        Slit mask            2193\n",
       "    HR 8011        ...                        Slit mask            2193\n",
       "    HR 8011        ...                        Slit mask            2193\n",
       "    HR 8011        ...                        Slit mask            2193\n",
       "    HR 8011        ...                        Slit mask            2193"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the observations by (target, wavelength) sequences\n",
    "\n",
    "# first, add a speckle session column that changes with each new target\n",
    "prev_target = \"\"\n",
    "speckle_session = 0\n",
    "dssi_observations[\"Speckle Session\"] = 0\n",
    "dssi_observations.sort(\"Time JD\")\n",
    "for observation in dssi_observations:\n",
    "    target_name = observation[\"Target Name\"]\n",
    "    if target_name != prev_target:\n",
    "        speckle_session += 1\n",
    "        prev_target = target_name\n",
    "    observation[\"Speckle Session\"] = speckle_session\n",
    "\n",
    "dssi_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=2193</i>\n",
       "<table id=\"table2825296030768\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Target Name</th><th>TIC ID</th><th>Speckle Session</th><th>StartTime JD</th><th>MidTime JD</th><th>EndTime JD</th><th>MidTime UTC</th><th>Num Sequences</th></tr></thead>\n",
       "<thead><tr><th>str12</th><th>str13</th><th>str4</th><th>float64</th><th>float64</th><th>float64</th><th>str19</th><th>int32</th></tr></thead>\n",
       "<tr><td>HR  583</td><td></td><td>1</td><td>2459849.8229166665</td><td>2459849.8229166665</td><td>2459849.8229166665</td><td>2022-09-27 07:45:00</td><td>1</td></tr>\n",
       "<tr><td>H007396</td><td></td><td>2</td><td>2459849.8256944446</td><td>2459849.8256944446</td><td>2459849.8256944446</td><td>2022-09-27 07:49:00</td><td>1</td></tr>\n",
       "<tr><td>H200063</td><td></td><td>3</td><td>2459849.8291666666</td><td>2459849.8291666666</td><td>2459849.8291666666</td><td>2022-09-27 07:54:00</td><td>1</td></tr>\n",
       "<tr><td>H011452</td><td></td><td>4</td><td>2459849.832638889</td><td>2459849.840625</td><td>2459849.8486111113</td><td>2022-09-27 08:10:30</td><td>7</td></tr>\n",
       "<tr><td>HR 0689</td><td></td><td>5</td><td>2459849.85</td><td>2459849.85</td><td>2459849.85</td><td>2022-09-27 08:24:00</td><td>1</td></tr>\n",
       "<tr><td>H200064</td><td></td><td>6</td><td>2459849.853472222</td><td>2459849.853472222</td><td>2459849.853472222</td><td>2022-09-27 08:29:00</td><td>1</td></tr>\n",
       "<tr><td>HR  737</td><td></td><td>7</td><td>2459849.855555556</td><td>2459849.855555556</td><td>2459849.855555556</td><td>2022-09-27 08:32:00</td><td>1</td></tr>\n",
       "<tr><td>H011565</td><td></td><td>8</td><td>2459849.857638889</td><td>2459849.857638889</td><td>2459849.857638889</td><td>2022-09-27 08:35:00</td><td>1</td></tr>\n",
       "<tr><td>H200065</td><td></td><td>9</td><td>2459849.859722222</td><td>2459849.859722222</td><td>2459849.859722222</td><td>2022-09-27 08:38:00</td><td>1</td></tr>\n",
       "<tr><td>HR  883</td><td></td><td>10</td><td>2459849.8618055554</td><td>2459849.8618055554</td><td>2459849.8618055554</td><td>2022-09-27 08:41:00</td><td>1</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>H204328</td><td></td><td>2184</td><td>2460458.9319444443</td><td>2460458.9319444443</td><td>2460458.9319444443</td><td>2024-05-28 10:22:00</td><td>1</td></tr>\n",
       "<tr><td>H204407</td><td></td><td>2185</td><td>2460458.933333333</td><td>2460458.933333333</td><td>2460458.933333333</td><td>2024-05-28 10:24:00</td><td>1</td></tr>\n",
       "<tr><td>HR 7794</td><td></td><td>2186</td><td>2460458.9347222224</td><td>2460458.9347222224</td><td>2460458.9347222224</td><td>2024-05-28 10:26:00</td><td>1</td></tr>\n",
       "<tr><td>HR 8216</td><td></td><td>2187</td><td>2460458.9375</td><td>2460458.9375</td><td>2460458.9375</td><td>2024-05-28 10:30:00</td><td>1</td></tr>\n",
       "<tr><td>H300131</td><td>TIC 278465736</td><td>2188</td><td>2460458.938888889</td><td>2460458.941319444</td><td>2460458.94375</td><td>2024-05-28 10:35:30</td><td>5</td></tr>\n",
       "<tr><td>HR 8216</td><td></td><td>2189</td><td>2460458.9465277777</td><td>2460458.9465277777</td><td>2460458.9465277777</td><td>2024-05-28 10:43:00</td><td>1</td></tr>\n",
       "<tr><td>H300093</td><td>TIC 414026507</td><td>2190</td><td>2460458.949305556</td><td>2460458.95625</td><td>2460458.9631944443</td><td>2024-05-28 10:57:00</td><td>9</td></tr>\n",
       "<tr><td>HR 8472</td><td></td><td>2191</td><td>2460458.965277778</td><td>2460458.965277778</td><td>2460458.965277778</td><td>2024-05-28 11:10:00</td><td>1</td></tr>\n",
       "<tr><td>H101769</td><td></td><td>2192</td><td>2460458.96875</td><td>2460458.973611111</td><td>2460458.978472222</td><td>2024-05-28 11:22:00</td><td>5</td></tr>\n",
       "<tr><td>HR 8011</td><td></td><td>2193</td><td>2460458.979861111</td><td>2460458.984722222</td><td>2460458.9895833335</td><td>2024-05-28 11:38:00</td><td>7</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=2193>\n",
       "Target Name     TIC ID    Speckle Session ...     MidTime UTC     Num Sequences\n",
       "   str12        str13           str4      ...        str19            int32    \n",
       "----------- ------------- --------------- ... ------------------- -------------\n",
       "    HR  583                             1 ... 2022-09-27 07:45:00             1\n",
       "    H007396                             2 ... 2022-09-27 07:49:00             1\n",
       "    H200063                             3 ... 2022-09-27 07:54:00             1\n",
       "    H011452                             4 ... 2022-09-27 08:10:30             7\n",
       "    HR 0689                             5 ... 2022-09-27 08:24:00             1\n",
       "    H200064                             6 ... 2022-09-27 08:29:00             1\n",
       "    HR  737                             7 ... 2022-09-27 08:32:00             1\n",
       "    H011565                             8 ... 2022-09-27 08:35:00             1\n",
       "    H200065                             9 ... 2022-09-27 08:38:00             1\n",
       "    HR  883                            10 ... 2022-09-27 08:41:00             1\n",
       "        ...           ...             ... ...                 ...           ...\n",
       "    H204328                          2184 ... 2024-05-28 10:22:00             1\n",
       "    H204407                          2185 ... 2024-05-28 10:24:00             1\n",
       "    HR 7794                          2186 ... 2024-05-28 10:26:00             1\n",
       "    HR 8216                          2187 ... 2024-05-28 10:30:00             1\n",
       "    H300131 TIC 278465736            2188 ... 2024-05-28 10:35:30             5\n",
       "    HR 8216                          2189 ... 2024-05-28 10:43:00             1\n",
       "    H300093 TIC 414026507            2190 ... 2024-05-28 10:57:00             9\n",
       "    HR 8472                          2191 ... 2024-05-28 11:10:00             1\n",
       "    H101769                          2192 ... 2024-05-28 11:22:00             5\n",
       "    HR 8011                          2193 ... 2024-05-28 11:38:00             7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# now, make a group summary of each wavelength in a speckle session\n",
    "dssi_sessions = Table(\n",
    "    names=[\"Target Name\", \"TIC ID\", \"Speckle Session\", \"StartTime JD\", \"MidTime JD\", \"EndTime JD\", \"MidTime UTC\", \"Num Sequences\"],\n",
    "    dtype=[\"str\", \"str\", \"str\", \"float\", \"float\", \"float\", \"str\", \"int\"],\n",
    ")\n",
    "\n",
    "obs_by_session = dssi_observations.group_by([\"Speckle Session\", \"Target Name\", \"TIC ID\"])\n",
    "for keys, observations in zip(obs_by_session.groups.keys, obs_by_session.groups):\n",
    "    start_time = observations[\"Time JD\"].min()\n",
    "    end_time = observations[\"Time JD\"].max()\n",
    "    mid_time = (end_time + start_time) / 2\n",
    "    mid_utc = str(Time(mid_time, format=\"jd\").iso)[:19] if mid_time > 0 else \"\"\n",
    "    dssi_sessions.add_row((keys[\"Target Name\"], keys[\"TIC ID\"], str(keys[\"Speckle Session\"]), start_time, mid_time, end_time, mid_utc, len(observations)))\n",
    "\n",
    "dssi_sessions.write(\"DSSI sessions.csv\", overwrite=True)\n",
    "dssi_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For observations of TIC objects, it looks like the average number of sequences is 6.24, a bit higher than I expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
